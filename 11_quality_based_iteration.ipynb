{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a382ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e5b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final quality: 0.8\n",
      "Total iterations: 2\n",
      "Final text: This is initial text. Improved version.\n"
     ]
    }
   ],
   "source": [
    "class QualityState(TypedDict):\n",
    "    text: str\n",
    "    quality_score: float\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    improvements: Annotated[list[str], add]\n",
    "\n",
    "def generate_text(state: QualityState) -> QualityState:\n",
    "    \"\"\"Generate or improve text\"\"\"\n",
    "    if state[\"iteration\"] == 0:\n",
    "        # First generation\n",
    "        text = \"This is initial text.\"\n",
    "    else:\n",
    "        # Improve existing text\n",
    "        text = state[\"text\"] + \" Improved version.\"\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"iteration\": state[\"iteration\"] + 1,\n",
    "        \"improvements\": [f\"Iteration {state['iteration'] + 1} completed\"]\n",
    "    }\n",
    "\n",
    "def evaluate_quality(state: QualityState) -> QualityState:\n",
    "    \"\"\"Evaluate text quality\"\"\"\n",
    "    # Simulate quality scoring (in real app, use actual metrics)\n",
    "    quality = min(0.5 + (state[\"iteration\"] * 0.15), 1.0)\n",
    "    \n",
    "    return {\"quality_score\": quality}\n",
    "\n",
    "def check_quality(state: QualityState) -> Literal[\"improve\", \"done\"]:\n",
    "    \"\"\"Decide if we need more iterations\"\"\"\n",
    "    # Exit if max iterations reached\n",
    "    if state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "        return \"done\"\n",
    "    \n",
    "    # Exit if quality is good enough\n",
    "    if state[\"quality_score\"] >= 0.8:\n",
    "        return \"done\"\n",
    "    \n",
    "    # Otherwise, improve more\n",
    "    return \"improve\"\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(QualityState)\n",
    "graph.add_node(\"generate\", generate_text)\n",
    "graph.add_node(\"evaluate\", evaluate_quality)\n",
    "\n",
    "graph.add_edge(START, \"generate\")\n",
    "graph.add_edge(\"generate\", \"evaluate\")\n",
    "graph.add_conditional_edges(\n",
    "    \"evaluate\",\n",
    "    check_quality,\n",
    "    {\n",
    "        \"improve\": \"generate\",  # Loop back!\n",
    "        \"done\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Run\n",
    "result = workflow.invoke({\n",
    "    \"text\": \"\",\n",
    "    \"quality_score\": 0.0,\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 10,\n",
    "    \"improvements\": []\n",
    "})\n",
    "\n",
    "print(f\"Final quality: {result['quality_score']}\")\n",
    "print(f\"Total iterations: {result['iteration']}\")\n",
    "print(f\"Final text: {result['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afa199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
